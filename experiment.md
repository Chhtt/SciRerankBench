# Detailed Experimental Settings

This page documents the **detailed experimental configurations** of SciRerankBench, including the evaluated LLM models and reranking methods. It serves as a standalone reference for reproducibility, benchmarking transparency, and fair comparison.

---

## ðŸ”¹ Detailed LLM Information

The LLM models evaluated in SciRerankBench span **five major LLM families**: **Mistral, LLaMA, DeepSeek, Qwen, and InternLM2**, with parameter sizes ranging from **7B to 671B+**.

### LLM Models

| Model            | Family        | Size |
| ---------------- | ------------- | ---- |
| Mistral-7B-v0.2  | Mistral       | 7B   |
| Mistral-24B      | Mistral       | 24B  |
| LLaMA-7B         | Meta (LLaMA)  | 7B   |
| LLaMA2-70B       | Meta (LLaMA2) | 70B  |
| DeepSeek-V3-7B   | DeepSeek      | 7B   |
| DeepSeek-V3-671B | DeepSeek      | 671B |
| Qwen-7B          | Qwen          | 7B   |
| Qwen-32B         | Qwen          | 32B  |
| Qwen-72B         | Qwen          | 72B  |
| InternLM2-7B     | InternLM2     | 7B   |
| InternLM2-20B    | InternLM2     | 20B  |

---

## ðŸ”¹ Detailed Reranker Information

The rerankers evaluated in SciRerankBench cover a broad spectrum of architectures, ranging from classical transformer models to LLM-based and agent-based systems.

### Reranking Models

| Model   | Category             | Reranking Strategy             |
| ------- | -------------------- | ------------------------------ |
| BGE     | Transformer          | Cross-Encoder                  |
| Jina    | Transformer          | Cross-Encoder                  |
| BCE     | Transformer          | Cross-Encoder                  |
| MXBAI   | Transformer          | Cross-Encoder                  |
| MiniLM  | Sentence Transformer | Distilled self-attention       |
| ColBert | BERT                 | Late interaction mechanism     |
| In-Rank | Seq2Seq model        | Tokenizes query-document pairs |
| SPLADE  | Sparse               | MLM-based sparse expansion     |
| RankT5  | T5-based             | Ranking losses                 |
| ListT5  | T5-based             | m-ary tournament sort          |
| Twolar  | T5-based             | Two-step distillation approach |
| LLM2Vec | LLM-based            | LLM embedding similarity       |
| RankGPT | LLM-based            | Sliding window reranking       |
| Rearank | Agent-based          | Reinforcement learning         |

---

## ðŸ§ª Detailed Experimental Results

This section reports the **main benchmark results** of SciRerankBench under different backbone LLMs and reranking paradigms.

### ðŸ”¹ Cross-Task & Cross-Subject Performance

The main experimental results are evaluated under two representative backbone LLMs:

* **Qwen-70B**
* **LLaMA2-70B**

These results report the performance of multiple rerankers across:

* Multiple tasks: `Multi-Hop`, `NC`, `CC`, `SSLI`, `Base`
* Multiple subjects: `Biology`, `Geography`, `Chemistry`, `Physics`, `Mathematics`

The comparison highlights:

* The **general effectiveness and robustness** of strong rerankers
* Only **minor performance variations across subjects**
* Strong **cross-domain generalization ability**


### Performance of different rerankers across various evaluation tasks (Qwen-70B) 

| Reranker    | Subject | Multi-Hop  | NC         | CC         | SSLI       | Base       |
| ----------- | ------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| **BCE**     | Bio.    | 55.08Â±2.62 | 53.57Â±2.20 | 51.66Â±0.48 | 51.89Â±1.40 | 63.48Â±0.57 |
| BCE         | Geo.    | 52.44Â±1.23 | 51.84Â±1.53 | 48.94Â±1.01 | 48.14Â±1.73 | 60.20Â±0.42 |
| BCE         | Chem.   | 53.62Â±2.08 | 52.65Â±0.81 | 49.74Â±1.22 | 49.44Â±2.50 | 59.61Â±0.75 |
| BCE         | Phy.    | 49.77Â±0.90 | 51.93Â±1.66 | 45.32Â±1.12 | 46.05Â±1.45 | 61.94Â±0.74 |
| BCE         | Math.   | 52.51Â±1.48 | 52.38Â±0.18 | 49.26Â±1.47 | 47.84Â±1.52 | 62.14Â±2.30 |
| **BGE**     | Bio.    | 54.55Â±1.70 | 53.56Â±2.00 | 55.52Â±0.79 | 54.56Â±1.16 | 64.74Â±0.71 |
| BGE         | Geo.    | 51.13Â±0.84 | 52.25Â±1.18 | 52.99Â±0.59 | 51.37Â±1.17 | 60.91Â±0.57 |
| BGE         | Chem.   | 52.15Â±1.62 | 53.00Â±0.55 | 52.88Â±1.55 | 51.01Â±0.89 | 60.47Â±1.39 |
| BGE         | Phy.    | 50.45Â±0.23 | 52.57Â±1.47 | 49.00Â±1.60 | 50.37Â±1.43 | 61.66Â±0.73 |
| BGE         | Math.   | 51.45Â±1.69 | 52.70Â±0.29 | 52.43Â±0.94 | 50.92Â±1.61 | 62.16Â±1.63 |
| **Jina**    | Bio.    | 51.52Â±1.78 | 53.89Â±1.87 | 53.22Â±0.83 | 51.87Â±1.28 | 62.85Â±0.78 |
| Jina        | Geo.    | 47.44Â±0.95 | 51.99Â±1.41 | 50.92Â±0.89 | 49.92Â±1.36 | 60.26Â±0.61 |
| Jina        | Chem.   | 49.74Â±1.16 | 52.54Â±0.73 | 52.20Â±1.45 | 51.97Â±2.40 | 59.20Â±0.79 |
| Jina        | Phy.    | 47.53Â±1.19 | 52.01Â±1.46 | 48.35Â±1.62 | 49.67Â±2.22 | 60.33Â±0.69 |
| Jina        | Math.   | 51.69Â±1.17 | 52.76Â±0.32 | 52.37Â±0.54 | 51.28Â±1.37 | 61.30Â±1.77 |
| **ListT5**  | Bio.    | 8.89Â±0.54  | 26.71Â±1.28 | 15.54Â±1.23 | 14.69Â±0.95 | 15.62Â±0.60 |
| ListT5      | Geo.    | 10.19Â±2.28 | 27.20Â±1.56 | 15.39Â±0.56 | 13.54Â±1.01 | 12.83Â±0.81 |
| ListT5      | Chem.   | 8.60Â±0.72  | 16.51Â±0.90 | 11.21Â±0.61 | 2.06Â±0.32  | 11.42Â±0.99 |
| ListT5      | Phy.    | 8.80Â±0.77  | 20.97Â±0.95 | 12.28Â±0.82 | 12.01Â±1.32 | 10.95Â±0.85 |
| ListT5      | Math.   | 9.17Â±1.19  | 28.30Â±1.46 | 13.68Â±0.74 | 13.41Â±0.94 | 12.71Â±0.89 |
| **MiniLM**  | Bio.    | 52.95Â±2.53 | 53.72Â±1.92 | 51.17Â±1.41 | 51.29Â±1.65 | 63.92Â±0.94 |
| MiniLM      | Geo.    | 48.78Â±0.38 | 51.75Â±1.74 | 48.82Â±1.30 | 48.18Â±2.28 | 60.29Â±0.70 |
| MiniLM      | Chem.   | 50.87Â±2.57 | 52.67Â±0.67 | 49.22Â±2.01 | 48.64Â±1.78 | 59.44Â±0.59 |
| MiniLM      | Phy.    | 46.71Â±1.17 | 52.24Â±1.70 | 45.25Â±0.74 | 46.55Â±3.55 | 60.98Â±0.66 |
| MiniLM      | Math.   | 49.64Â±1.64 | 52.77Â±0.69 | 49.15Â±0.48 | 47.83Â±2.21 | 61.75Â±0.50 |
| **RankT5**  | Bio.    | 14.98Â±1.77 | 34.12Â±1.99 | 21.08Â±1.62 | 20.64Â±2.36 | 19.18Â±0.59 |
| RankT5      | Geo.    | 16.78Â±1.76 | 34.69Â±1.10 | 22.76Â±1.31 | 19.44Â±2.47 | 19.57Â±1.55 |
| RankT5      | Chem.   | 12.06Â±1.61 | 21.89Â±0.29 | 17.04Â±0.63 | 49.44Â±0.87 | 11.32Â±0.54 |
| RankT5      | Phy.    | 14.83Â±0.78 | 27.76Â±1.34 | 18.48Â±2.70 | 18.89Â±2.50 | 14.00Â±1.23 |
| RankT5      | Math.   | 18.73Â±0.76 | 35.56Â±0.91 | 21.57Â±4.64 | 20.37Â±1.78 | 18.47Â±0.29 |
| **SPLADE**  | Bio.    | 14.16Â±1.12 | 34.28Â±2.45 | 23.40Â±1.51 | 19.05Â±1.26 | 19.04Â±0.48 |
| SPLADE      | Geo.    | 17.27Â±0.37 | 34.26Â±1.30 | 22.45Â±1.28 | 20.65Â±0.55 | 19.39Â±1.10 |
| SPLADE      | Chem.   | 12.31Â±1.51 | 21.84Â±0.77 | 18.35Â±1.95 | 42.71Â±3.13 | 10.66Â±0.02 |
| SPLADE      | Phy.    | 14.21Â±1.25 | 28.27Â±1.96 | 20.49Â±1.81 | 21.10Â±2.76 | 14.43Â±0.44 |
| SPLADE      | Math.   | 19.05Â±0.53 | 35.26Â±0.27 | 20.39Â±3.23 | 20.30Â±2.48 | 18.58Â±0.47 |
| **TwoLAR**  | Bio.    | 53.69Â±1.41 | 53.53Â±2.04 | 56.17Â±0.72 | 57.24Â±1.11 | 63.55Â±0.84 |
| TwoLAR      | Geo.    | 50.78Â±0.42 | 52.05Â±1.76 | 55.36Â±0.96 | 53.59Â±1.30 | 61.12Â±0.54 |
| TwoLAR      | Chem.   | 52.02Â±2.02 | 53.05Â±0.69 | 54.20Â±1.66 | 53.40Â±0.85 | 60.13Â±0.48 |
| TwoLAR      | Phy.    | 49.57Â±1.20 | 52.40Â±1.70 | 51.65Â±0.90 | 52.19Â±1.05 | 61.91Â±0.37 |
| TwoLAR      | Math.   | 52.10Â±1.39 | 53.07Â±0.47 | 54.33Â±0.23 | 52.90Â±1.60 | 62.43Â±0.41 |
| **ColBert** | Bio.    | 53.35Â±1.96 | 53.63Â±1.98 | 44.92Â±0.32 | 44.38Â±0.74 | 62.87Â±0.69 |
| ColBert     | Geo.    | 50.35Â±0.93 | 51.60Â±1.75 | 41.09Â±0.51 | 40.27Â±1.68 | 60.32Â±0.26 |
| ColBert     | Chem.   | 52.07Â±1.80 | 52.82Â±0.65 | 42.12Â±1.04 | 42.24Â±1.51 | 58.96Â±0.88 |
| ColBert     | Phy.    | 49.25Â±1.09 | 52.30Â±1.38 | 40.30Â±0.74 | 39.19Â±2.83 | 61.10Â±0.46 |
| ColBert     | Math.   | 51.12Â±0.79 | 52.68Â±0.26 | 41.97Â±0.82 | 41.25Â±2.11 | 61.74Â±0.70 |
| **MXBAI**   | Bio.    | 53.56Â±3.25 | 53.62Â±1.71 | 57.18Â±0.53 | 58.40Â±0.96 | 62.25Â±0.67 |
| MXBAI       | Geo.    | 49.26Â±1.22 | 51.72Â±1.48 | 56.45Â±0.43 | 55.40Â±1.63 | 59.67Â±0.64 |
| MXBAI       | Chem.   | 51.43Â±1.56 | 53.05Â±0.59 | 54.29Â±1.12 | 55.42Â±1.05 | 58.83Â±0.47 |
| MXBAI       | Phy.    | 48.57Â±0.74 | 52.29Â±1.82 | 53.33Â±0.34 | 54.45Â±1.89 | 61.09Â±0.70 |
| MXBAI       | Math.   | 50.29Â±2.11 | 52.92Â±0.16 | 56.61Â±0.44 | 54.39Â±2.41 | 61.02Â±0.40 |
| **T5**      | Bio.    | 54.45Â±1.46 | 53.64Â±1.75 | 53.92Â±1.13 | 53.81Â±1.17 | 63.96Â±0.99 |
| T5          | Geo.    | 51.08Â±1.04 | 51.87Â±1.64 | 52.46Â±0.78 | 51.40Â±0.54 | 60.65Â±0.06 |
| T5          | Chem.   | 53.08Â±1.68 | 52.76Â±0.59 | 52.44Â±1.87 | 51.66Â±0.98 | 59.67Â±0.94 |
| T5          | Phy.    | 50.41Â±0.86 | 52.20Â±1.23 | 49.11Â±1.03 | 48.59Â±2.62 | 61.44Â±0.76 |
| T5          | Math.   | 52.37Â±1.38 | 52.66Â±0.31 | 52.95Â±0.25 | 51.28Â±2.12 | 62.14Â±0.55 |

### Performance of different rerankers across various evaluation tasks (LLaMA2-70B)

| Reranker    | Subject | Multi-Hop  | NC         | CC         | SSLI       | Base       |
| ----------- | ------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| **BCE**     | Bio.    | 48.97Â±1.83 | 51.82Â±0.48 | 49.73Â±0.89 | 50.50Â±1.35 | 60.57Â±0.48 |
| BCE         | Geo.    | 50.32Â±1.20 | 51.94Â±0.70 | 47.85Â±0.95 | 48.30Â±1.40 | 59.12Â±0.65 |
| BCE         | Chem.   | 50.40Â±1.15 | 51.40Â±0.60 | 48.92Â±1.05 | 49.40Â±1.20 | 58.84Â±0.73 |
| BCE         | Phy.    | 48.36Â±1.32 | 51.55Â±0.88 | 45.21Â±0.90 | 46.82Â±1.48 | 61.78Â±1.12 |
| BCE         | Math.   | 49.55Â±1.18 | 51.68Â±1.12 | 49.50Â±1.00 | 48.96Â±1.33 | 60.88Â±1.40 |
| **BGE**     | Bio.    | 52.08Â±1.66 | 52.84Â±0.36 | 52.32Â±1.25 | 53.63Â±1.10 | 60.95Â±0.74 |
| BGE         | Geo.    | 51.67Â±1.45 | 52.67Â±0.59 | 49.35Â±0.83 | 51.48Â±1.18 | 60.42Â±0.55 |
| BGE         | Chem.   | 51.74Â±1.30 | 52.40Â±0.64 | 50.23Â±1.00 | 51.92Â±1.35 | 60.26Â±0.88 |
| BGE         | Phy.    | 50.86Â±1.17 | 52.55Â±0.74 | 47.96Â±1.08 | 50.12Â±1.29 | 62.20Â±1.15 |
| BGE         | Math.   | 52.11Â±1.25 | 52.69Â±0.77 | 51.12Â±0.91 | 52.23Â±1.31 | 61.03Â±1.20 |
| **Jina**    | Bio.    | 47.34Â±1.38 | 53.19Â±0.67 | 52.00Â±0.65 | 51.41Â±1.55 | 60.38Â±1.19 |
| Jina        | Geo.    | 47.67Â±1.05 | 52.51Â±0.74 | 49.28Â±1.10 | 49.21Â±1.40 | 59.01Â±1.30 |
| Jina        | Chem.   | 48.20Â±1.25 | 52.13Â±0.85 | 50.01Â±1.03 | 49.97Â±1.32 | 58.32Â±1.20 |
| Jina        | Phy.    | 46.33Â±1.36 | 52.60Â±0.92 | 47.39Â±1.07 | 47.88Â±1.45 | 61.14Â±1.08 |
| Jina        | Math.   | 47.75Â±1.12 | 52.88Â±0.68 | 50.23Â±1.01 | 49.66Â±1.44 | 60.42Â±1.22 |
| **ListT5**  | Bio.    | 16.70Â±0.29 | 25.82Â±1.73 | 25.69Â±1.19 | 26.42Â±0.42 | 26.23Â±1.57 |
| ListT5      | Geo.    | 10.19Â±2.28 | 27.20Â±1.56 | 15.39Â±0.56 | 13.54Â±1.01 | 12.83Â±0.81 |
| ListT5      | Chem.   | 8.60Â±0.72  | 16.51Â±0.90 | 11.21Â±0.61 | 2.06Â±0.32  | 11.42Â±0.99 |
| ListT5      | Phy.    | 8.80Â±0.77  | 20.97Â±0.95 | 12.28Â±0.82 | 12.01Â±1.32 | 10.95Â±0.85 |
| ListT5      | Math.   | 9.17Â±1.19  | 28.30Â±1.46 | 13.68Â±0.74 | 13.41Â±0.94 | 12.71Â±0.89 |
| **MiniLM**  | Bio.    | 48.14Â±1.91 | 51.68Â±0.32 | 49.83Â±0.35 | 50.19Â±1.59 | 60.56Â±0.83 |
| MiniLM      | Geo.    | 49.20Â±1.45 | 51.33Â±0.39 | 47.55Â±0.67 | 48.72Â±1.51 | 59.37Â±0.61 |
| MiniLM      | Chem.   | 48.97Â±1.33 | 51.11Â±0.45 | 48.40Â±0.58 | 49.45Â±1.34 | 59.06Â±0.78 |
| MiniLM      | Phy.    | 47.25Â±1.12 | 51.26Â±0.52 | 45.71Â±0.62 | 46.91Â±1.47 | 61.34Â±0.91 |
| MiniLM      | Math.   | 48.45Â±1.28 | 51.38Â±0.48 | 48.73Â±0.59 | 49.18Â±1.46 | 60.61Â±0.85 |
| **RankT5**  | Bio.    | 49.45Â±2.88 | 52.41Â±0.61 | 51.07Â±0.03 | 51.33Â±1.57 | 60.49Â±0.21 |
| RankT5      | Geo.    | 50.11Â±2.02 | 52.10Â±0.57 | 48.84Â±0.72 | 50.08Â±1.49 | 59.73Â±0.42 |
| RankT5      | Chem.   | 49.85Â±1.89 | 51.78Â±0.62 | 49.71Â±0.60 | 50.89Â±1.40 | 59.61Â±0.64 |
| RankT5      | Phy.    | 48.23Â±1.74 | 52.05Â±0.68 | 47.22Â±0.65 | 48.98Â±1.47 | 61.41Â±0.72 |
| RankT5      | Math.   | 49.35Â±2.03 | 52.17Â±0.66 | 50.26Â±0.51 | 50.70Â±1.35 | 60.55Â±0.85 |
| **SPLADE**  | Bio.    | 45.21Â±1.67 | 52.62Â±0.56 | 43.96Â±0.75 | 45.38Â±1.35 | 59.05Â±0.52 |
| SPLADE      | Geo.    | 45.62Â±1.21 | 52.38Â±0.67 | 42.41Â±0.89 | 43.76Â±1.50 | 58.30Â±0.40 |
| SPLADE      | Chem.   | 45.95Â±1.00 | 52.12Â±0.74 | 42.85Â±0.93 | 44.44Â±1.42 | 57.78Â±0.60 |
| SPLADE      | Phy.    | 44.16Â±1.09 | 52.33Â±0.59 | 40.92Â±0.95 | 42.88Â±1.51 | 60.22Â±0.73 |
| SPLADE      | Math.   | 44.90Â±1.30 | 52.50Â±0.62 | 43.50Â±0.88 | 44.48Â±1.53 | 59.11Â±0.90 |
| **TwoLAR**  | Bio.    | 50.66Â±2.18 | 52.57Â±0.87 | 54.50Â±0.27 | 55.16Â±0.89 | 60.15Â±0.04 |
| TwoLAR      | Geo.    | 51.12Â±1.55 | 52.44Â±0.72 | 51.58Â±0.61 | 52.75Â±0.91 | 59.40Â±0.27 |
| TwoLAR      | Chem.   | 51.30Â±1.29 | 52.13Â±0.64 | 52.62Â±0.52 | 53.66Â±0.97 | 59.23Â±0.32 |
| TwoLAR      | Phy.    | 50.20Â±1.46 | 52.34Â±0.67 | 50.15Â±0.59 | 51.41Â±0.86 | 61.55Â±0.58 |
| TwoLAR      | Math.   | 50.89Â±1.34 | 52.47Â±0.71 | 53.22Â±0.44 | 53.83Â±0.87 | 60.33Â±0.61 |
| **ColBert** | Bio.    | 49.23Â±1.92 | 52.52Â±1.24 | 43.49Â±0.51 | 44.99Â±1.50 | 59.76Â±1.50 |
| ColBert     | Geo.    | 49.40Â±1.63 | 52.39Â±1.05 | 41.88Â±0.94 | 43.57Â±1.65 | 58.91Â±1.42 |
| ColBert     | Chem.   | 49.10Â±1.45 | 52.15Â±1.12 | 42.41Â±0.92 | 44.15Â±1.49 | 58.73Â±1.35 |
| ColBert     | Phy.    | 48.11Â±1.76 | 52.28Â±1.09 | 40.55Â±0.87 | 42.28Â±1.62 | 61.12Â±1.23 |
| ColBert     | Math.   | 48.80Â±1.81 | 52.36Â±1.18 | 43.12Â±0.83 | 44.09Â±1.63 | 59.81Â±1.38 |
| **MXBAI**   | Bio.    | 49.18Â±2.16 | 53.41Â±0.27 | 55.75Â±0.87 | 56.04Â±1.19 | 59.77Â±1.65 |
| MXBAI       | Geo.    | 49.55Â±1.88 | 53.22Â±0.40 | 53.01Â±0.66 | 53.83Â±1.24 | 58.89Â±1.53 |
| MXBAI       | Chem.   | 49.62Â±1.42 | 52.95Â±0.47 | 54.12Â±0.74 | 54.49Â±1.13 | 58.70Â±1.40 |
| MXBAI       | Phy.    | 48.58Â±1.36 | 53.20Â±0.54 | 52.46Â±0.68 | 52.76Â±1.22 | 61.33Â±1.45 |
| MXBAI       | Math.   | 49.35Â±1.63 | 53.33Â±0.51 | 55.12Â±0.59 | 54.88Â±1.20 | 59.89Â±1.52 |
| **T5**      | Bio.    | 51.47Â±2.23 | 53.30Â±1.08 | 51.80Â±0.62 | 52.73Â±1.31 | 59.95Â±0.25 |
| T5          | Geo.    | 51.91Â±1.89 | 53.01Â±0.92 | 49.50Â±0.55 | 50.62Â±1.24 | 59.20Â±0.33 |
| T5          | Chem.   | 51.86Â±1.74 | 52.60Â±0.89 | 50.36Â±0.47 | 51.31Â±1.25 | 59.10Â±0.41 |
| T5          | Phy.    | 50.78Â±1.60 | 52.96Â±1.02 | 48.42Â±0.51 | 49.66Â±1.31 | 61.48Â±0.35 |
| T5          | Math.   | 51.55Â±1.95 | 53.13Â±1.00 | 51.02Â±0.46 | 51.40Â±1.29 | 60.01Â±0.39 |

---

### ðŸ”¹ Architectural Paradigm Comparison

We further conduct a focused comparison between two representative paradigms:

* **LLM-based reranker**: `LLM2Vec`
* **Agent-based reranker**: `Rearank`

This analysis provides insights into how different **architectural designs** and **inference paradigms** behave under the same evaluation settings.

### Performance of LLM-based and Agent-based rerankers across various evaluation tasks

| Reranker    | Subject | Multi-Hop  | NC         | CC         | SSLI       | Base       |
| ----------- | ------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| **LLM2Vec** | Bio.    | 33.72Â±0.36 | 32.77Â±0.45 | 31.78Â±0.52 | 31.34Â±0.61 | 31.46Â±0.50 |
| LLM2Vec     | Geo.    | 44.34Â±3.09 | 41.84Â±2.70 | 38.45Â±2.10 | 37.06Â±1.85 | 35.99Â±1.75 |
| LLM2Vec     | Chem.   | 55.28Â±0.84 | 53.75Â±0.88 | 51.35Â±1.10 | 49.39Â±1.05 | 49.45Â±0.90 |
| LLM2Vec     | Phy.    | 50.18Â±0.83 | 47.82Â±0.75 | 44.42Â±0.82 | 43.96Â±0.65 | 45.69Â±0.88 |
| LLM2Vec     | Math.   | 33.04Â±0.66 | 29.49Â±1.10 | 31.05Â±0.92 | 29.26Â±1.15 | 28.99Â±1.90 |
| **Rearank** | Bio.    | 49.98Â±0.79 | 48.57Â±1.27 | 47.11Â±0.81 | 46.48Â±2.16 | 46.69Â±0.94 |
| Rearank     | Geo.    | 32.56Â±1.36 | 30.73Â±1.92 | 26.71Â±2.38 | 24.83Â±0.84 | 23.48Â±1.17 |
| Rearank     | Chem.   | 49.87Â±1.67 | 48.51Â±0.88 | 46.32Â±1.21 | 44.56Â±1.18 | 44.64Â±0.61 |
| Rearank     | Phy.    | 52.25Â±0.46 | 49.76Â±0.23 | 46.27Â±0.70 | 45.86Â±0.32 | 47.64Â±0.87 |
| Rearank     | Math.   | 51.45Â±1.02 | 45.90Â±1.34 | 48.35Â±0.50 | 45.62Â±1.23 | 45.22Â±3.21 |


