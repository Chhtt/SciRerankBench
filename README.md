# SciRerankBench

SciRerankBench is a comprehensive benchmark designed to systematically evaluate **reranking models (rerankers)** in the context of **scientific Retrieval-Augmented Generation (RAG) systems**. The benchmark focuses on scientific literature scenarios, aiming to measure how well different reranking architectures improve retrieval quality and downstream LLM generation performance. Our dataset is avaliable in https://drive.google.com/drive/folders/16TKkEezhA7wnzsoFMi50d2VoqWx6G8q5?usp=drive_link

This repository accompanies the arXiv paper:

> **SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs**
> *([arXiv link](https://arxiv.org/abs/2508.08742))*

---

## ðŸ“„ Citation

If you use SciRerankBench in your research, please cite:

```bibtex
@article{chen2025scirerankbench,
  title={SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs},
  author={Chen, Haotian and Long, Qingqing and Xiao, Meng and Luo, Xiao and Ju, Wei and Wang, Chengrui and Wang, Xuezhi and Zhou, Yuanchun and Zhu, Hengshu},
  journal={arXiv preprint arXiv:2508.08742},
  year={2025}
}
```

